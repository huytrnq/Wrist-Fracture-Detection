{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "GiSQFoSZ5zpZ"
      },
      "outputs": [],
      "source": [
        "## Import system library\n",
        "import os\n",
        "import glob\n",
        "\n",
        "## Import Image Processing library\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skimage\n",
        "from skimage import exposure\n",
        "from skimage.color import rgb2gray\n",
        "from scipy.ndimage import convolve, uniform_filter\n",
        "from skimage.filters import gabor_kernel, unsharp_mask, threshold_otsu, gabor\n",
        "from skimage.morphology import disk, closing, dilation\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "## Import machine learning library\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from skimage.feature import hog\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "\n",
        "from utils.vis import draw_bboxes\n",
        "from utils.dataset import sliding_window\n",
        "from utils.dataset import load_yolo_labels\n",
        "from utils.bboxes import iou, calculate_boxA_percentage\n",
        "from utils.intensity_transforms import histogram_matching, calculate_mean_histogram\n",
        "from utils.dataset import adjust_labels_for_pooling, resize_image_and_bboxes\n",
        "from models.kernels import AlexNetDescriptor, CannyDescriptor, HogDescriptor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "IPxEOjKy7bT7"
      },
      "outputs": [],
      "source": [
        "## Defind dataset folders\n",
        "\n",
        "# root_path = '/content/drive/Shareddrives/Wrist_fracture_detectiom/ML/Dataset'\n",
        "root_path = 'MLDataset/crop_data'\n",
        "\n",
        "img_train_folder = 'train'\n",
        "img_test_folder = 'test'\n",
        "label_folder = 'labels'\n",
        "image_folder = 'images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_features(export_path, name, feature_name, feature_list):\n",
        "    \"\"\"Save features to npy file\n",
        "\n",
        "    Args:\n",
        "        export_path (str): path to save the file\n",
        "        name (str): file name to save\n",
        "        feature_name (str): name of the feature. Ex: 'lbp', 'hog', 'gabor'\n",
        "        feature_list (list/array): list of features\n",
        "    \"\"\"\n",
        "    ## Export features to file\n",
        "    save_name = f'{name}_{feature_name}.npy'\n",
        "    save_path = os.path.join(export_path, save_name)\n",
        "    np.save(save_path, feature_list)\n",
        "    print(f'Save {feature_name} features to {save_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Histogram Matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "## Calculate mean histogram\n",
        "image_files = glob.glob(os.path.join(root_path, image_folder, 'train/**/*.png'), recursive=True)\n",
        "mean_histogram = calculate_mean_histogram(image_files)\n",
        "### Export mean histogram to npy file\n",
        "np.save('mean_hist.npy', mean_histogram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Visualize the mean histogram\n",
        "for i, image_file in enumerate(image_files):\n",
        "    if i > 1:\n",
        "        break\n",
        "    image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
        "    matched_img = histogram_matching(image, mean_histogram)\n",
        "    ax, fig = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    fig[0].imshow(image)\n",
        "    fig[1].imshow(matched_img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31rBucvf_Cue"
      },
      "source": [
        "## Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(image, mean_histogram=None, dilate_num=4, intensity_crop=1, outputbitdepth=8, unsharp=True):\n",
        "    \"\"\"\n",
        "    Processes a single image by applying histogram matching, thresholding,\n",
        "    multiple dilations, and closing.\n",
        "\n",
        "    Args:\n",
        "    - image_path (str/numpy): Path to the image file or numpy array of the image.\n",
        "    - mean_histogram (array-like): The histogram to match. If None, don't match histogram.\n",
        "    - dilate_num (int): Number of times dilation should be applied.\n",
        "    - intensity_crop (int): Percentage of the image intensity to crop.\n",
        "    - outputbitdepth (int): The bit depth of the output image.\n",
        "\n",
        "    Returns:\n",
        "    - final_image (ndarray): The processed image.\n",
        "    \"\"\"\n",
        "    if isinstance(image, str):\n",
        "        image = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
        "    elif isinstance(image, np.ndarray):\n",
        "        if image.ndim == 3:\n",
        "            image = rgb2gray(image)\n",
        "    else:\n",
        "        raise ValueError(\"Image must be a file path or numpy array.\")\n",
        "    \n",
        "    if unsharp:\n",
        "        image = ((unsharp_mask(image, radius=2, amount=1))*255).clip(0, 255).astype(np.uint8) # unsharp mask to enhance edges\n",
        "\n",
        "    ## Histogram equalization\n",
        "    image = exposure.rescale_intensity(image, in_range=(np.percentile(image, intensity_crop), np.percentile(image, (100-intensity_crop))))\n",
        "    image = exposure.equalize_adapthist(image)\n",
        "\n",
        "    \n",
        "    ## Normalize image\n",
        "    image = cv2.normalize(image, dst=None, alpha=0, beta=int((pow(2, outputbitdepth))-1), norm_type=cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    \n",
        "    # Apply histogram matching (assuming this function is defined elsewhere)\n",
        "    if mean_histogram is not None:  \n",
        "        image = histogram_matching(image, mean_histogram)\n",
        "    \n",
        "    # Apply Otsu's thresholding\n",
        "    thresh = threshold_otsu(image)\n",
        "    binary_mask = image > thresh\n",
        "    \n",
        "    # Convert boolean mask to 8-bit integer\n",
        "    binary_mask = binary_mask.astype(np.uint8) * 255  # Convert boolean to uint8\n",
        "    \n",
        "    # Apply multiple dilations\n",
        "    selem = disk(4)\n",
        "    dilated_mask = binary_mask\n",
        "    for _ in range(dilate_num):\n",
        "        dilated_mask = dilation(dilated_mask, selem)\n",
        "    \n",
        "    # Apply closing to the dilated mask\n",
        "    closed_mask = closing(dilated_mask, selem)\n",
        "\n",
        "    contours, _ = cv2.findContours(closed_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    # Find the largest contour based on area\n",
        "    max_area = 0\n",
        "    largest_contour = None\n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > max_area:\n",
        "            max_area = area\n",
        "            largest_contour = contour\n",
        "    \n",
        "    # Create a mask for the largest contour\n",
        "    if largest_contour is not None:\n",
        "        mask = np.zeros_like(binary_mask)\n",
        "        cv2.drawContours(mask, [largest_contour], -1, (255), thickness=cv2.FILLED)\n",
        "    \n",
        "        # Apply the mask to the original image\n",
        "        final_image = cv2.bitwise_and(image, image, mask=mask)\n",
        "    \n",
        "    return final_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_image_and_labels(image_path, mean_histogram, intensity_crop, outputbitdepth, unsharp, pool_size=(4,4), resize=None):\n",
        "    \"\"\"\n",
        "    Processes an image by preprocessing and loading corresponding labels, then applies pooling.\n",
        "\n",
        "    Args:\n",
        "    image_path (str): Path to the image file.\n",
        "    mean_histogram (bool): Flag for histogram processing.\n",
        "    intensity_crop (tuple): Intensity cropping parameters.\n",
        "    outputbitdepth (int): Bit depth for image output.\n",
        "    unsharp (bool): Flag for unsharp mask processing.\n",
        "    pool_size (tuple): Size of the pooling window.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the processed image and associated labels.\n",
        "    \"\"\"\n",
        "    labels = []\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "    ### Parse label from yolo format\n",
        "    image_name = os.path.basename(image_path)\n",
        "    label_path = image_path.replace('images', 'labels').replace('.png', '.txt')\n",
        "    if os.path.exists(label_path):\n",
        "        labels = load_yolo_labels(label_path, img.shape, [3]) # 3 is the class index for fracture\n",
        "    \n",
        "    ## Preprocess image\n",
        "    img = preprocess(img, mean_histogram=mean_histogram, intensity_crop=intensity_crop, outputbitdepth=outputbitdepth, unsharp=unsharp)\n",
        "    \n",
        "    # Apply pooling to downscale the image for computation efficiency and remain important characteristics features\n",
        "    if pool_size is not None:\n",
        "        img = skimage.measure.block_reduce(img, pool_size, np.max)\n",
        "        # Adjust labels for pooling\n",
        "        labels = adjust_labels_for_pooling(labels, img.shape, pool_size)\n",
        "    if resize:\n",
        "        img, labels = resize_image_and_bboxes(img, labels, resize)\n",
        "        \n",
        "    return img, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [],
      "source": [
        "import skimage.measure\n",
        "\n",
        "## Extract features from an image using a given descriptor with sliding window\n",
        "def feature_extraction(image_path, mean_histogram, intensity_crop, outputbitdepth, unsharp, descriptor, stepSize=128, windowSize=256, pool_size=(4, 4), heatmap=None):\n",
        "    \"\"\"\n",
        "    Extract features from an image using a given descriptor.\n",
        "\n",
        "    Args:\n",
        "    - image_path (str): Path to the image file.\n",
        "    - mean_histogram (array-like): The histogram to match. If None, don't match histogram.\n",
        "    - intensity_crop (int): Percentage of the image intensity to crop.\n",
        "    - outputbitdepth (int): The bit depth of the output image.\n",
        "    - unsharp (bool): Flag for unsharp mask processing.\n",
        "    - descriptor (object): The descriptor object to use for feature extraction.\n",
        "    - show_grid (bool): Flag to show the grid of windows.\n",
        "\n",
        "    Returns:\n",
        "    - features (list): List of features extracted from the image.\n",
        "    - labels_list (list): List of labels for each feature.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    labels_list = []\n",
        "    image, labels = process_image_and_labels(image_path, mean_histogram, intensity_crop, outputbitdepth, unsharp, pool_size)\n",
        "    ## scale heatmap to the same size as the image\n",
        "    if heatmap is not None:\n",
        "        heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
        "    \n",
        "    # feature_image = image     \n",
        "\n",
        "    for i, (x, y, window_f) in enumerate(sliding_window(image, stepSize=stepSize, windowSize=windowSize)):\n",
        "        if window_f.shape[0] != windowSize or window_f.shape[1] != windowSize:\n",
        "            continue\n",
        "        # ## Image histogram \n",
        "        window_f = skimage.measure.block_reduce(window_f, (2, 2), np.max)\n",
        "        # Calculate the percentage of zero values\n",
        "        zero_percentage = np.mean(window_f == 0) * 100\n",
        "        if zero_percentage > 50:\n",
        "            continue\n",
        "        \n",
        "        feature_image = descriptor(window_f)     \n",
        "        feature = feature_image.ravel()\n",
        "        if heatmap is not None:\n",
        "            feature = np.append(feature, heatmap[y:y+windowSize, x:x+windowSize].ravel())\n",
        "        \n",
        "        iou_score = 0\n",
        "        class_id = 0\n",
        "        for label in labels:\n",
        "            c, *xyxy = label\n",
        "            iou_score = calculate_boxA_percentage(xyxy, [x, y, x + windowSize, y + windowSize])\n",
        "            if iou_score > 0.5:\n",
        "                class_id = 1\n",
        "            elif iou_score > 0.1 and iou_score < 0.5:\n",
        "                class_id = 0\n",
        "        \n",
        "        features.append(feature)\n",
        "        labels_list.append(class_id)\n",
        "            \n",
        "    return features, labels_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters for feature extraction\n",
        "windowSize = 64\n",
        "stepSize = 32\n",
        "pool_size = (4, 4)\n",
        "outputbitdepth = 8 # Set output bit depth\n",
        "unsharp = True # Sharpen image\n",
        "equalize = True # CLAHE contrast enhancement\n",
        "intensity_crop = 0.1 # Set rescale intensity crop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HOG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Extract HOG features and export to npy file\n",
        "hogdes = HogDescriptor()\n",
        "\n",
        "modes = [\"train\", \"test\"]\n",
        "class_names = [\"fracture\", \"normal\"]\n",
        "\n",
        "for mode in modes:\n",
        "    for class_name in class_names:\n",
        "        features_list = []\n",
        "        labels_list = []\n",
        "        image_files = glob.glob(\n",
        "            os.path.join(root_path, image_folder, mode, class_name, \"*.png\")\n",
        "        )\n",
        "        ### Loop through all images\n",
        "        for idx, image_path in enumerate(image_files):\n",
        "            print(f\"Processing {idx}/{len(image_files)} : {image_path}\")\n",
        "            features, labels = feature_extraction(\n",
        "                image_path,\n",
        "                mean_histogram,\n",
        "                intensity_crop,\n",
        "                outputbitdepth,\n",
        "                unsharp,\n",
        "                hogdes,\n",
        "                stepSize=stepSize,\n",
        "                windowSize=windowSize,\n",
        "                pool_size=pool_size,\n",
        "                # heatmap=probability_heatmap,\n",
        "            )\n",
        "            features_list.extend(features)\n",
        "            labels_list.extend(labels)\n",
        "        print(\"=\" * 50 + \"Done\" + \"=\" * 50)\n",
        "        name = mode + \"_\" + class_name\n",
        "        export_features(\n",
        "            export_path=root_path,\n",
        "            name=name,\n",
        "            feature_name=\"hog\",\n",
        "            feature_list=features_list,\n",
        "        )\n",
        "        export_features(\n",
        "            export_path=root_path,\n",
        "            name=name,\n",
        "            feature_name=\"labels_hog\",\n",
        "            feature_list=labels_list,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hog - Canny Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Hog features from Canny edges and export to npy file\n",
        "modes = [\"train\", \"test\"]\n",
        "class_names = [\"fracture\", \"normal\"]\n",
        "\n",
        "canny_descriptor = CannyDescriptor()\n",
        "\n",
        "for mode in modes:\n",
        "    for class_name in class_names:\n",
        "        features_list = []\n",
        "        labels_list = []\n",
        "        image_files = glob.glob(\n",
        "            os.path.join(root_path, image_folder, mode, class_name, \"*.png\")\n",
        "        )\n",
        "        ### Loop through all images\n",
        "        for idx, image_path in enumerate(image_files):\n",
        "            print(f\"Processing {idx}/{len(image_files)} : {image_path}\")\n",
        "            features, labels = feature_extraction(\n",
        "                image_path,\n",
        "                mean_histogram,\n",
        "                intensity_crop,\n",
        "                outputbitdepth,\n",
        "                unsharp,\n",
        "                canny_descriptor,\n",
        "                stepSize=stepSize,\n",
        "                windowSize=windowSize,\n",
        "                # heatmap=probability_heatmap,\n",
        "            )\n",
        "            features_list.extend(features)\n",
        "            labels_list.extend(labels)\n",
        "        print(\"=\" * 50 + \"Done\" + \"=\" * 50)\n",
        "        name = mode + \"_\" + class_name\n",
        "        export_features(\n",
        "            export_path=root_path,\n",
        "            name=name,\n",
        "            feature_name=\"hog_canny\",\n",
        "            feature_list=features_list,\n",
        "        )\n",
        "        export_features(\n",
        "            export_path=root_path,\n",
        "            name=name,\n",
        "            feature_name=\"labels_hog_canny\",\n",
        "            feature_list=labels_list,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AlexNet Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Gabor features from AlexNet's first layer and export to npy file\n",
        "modes = [\"train\", \"test\"]\n",
        "class_names = [\"fracture\", \"normal\"]\n",
        "\n",
        "alexnet_descriptor = AlexNetDescriptor()\n",
        "\n",
        "for mode in modes:\n",
        "    for class_name in class_names:\n",
        "        features_list = []\n",
        "        labels_list = []\n",
        "        image_files = glob.glob(\n",
        "            os.path.join(root_path, image_folder, mode, class_name, \"*.png\")\n",
        "        )\n",
        "        ### Loop through all images\n",
        "        for idx, image_path in enumerate(image_files):\n",
        "            print(f\"Processing {idx}/{len(image_files)} : {image_path}\")\n",
        "            features, labels = feature_extraction(\n",
        "                image_path,\n",
        "                mean_histogram,\n",
        "                intensity_crop,\n",
        "                outputbitdepth,\n",
        "                unsharp,\n",
        "                alexnet_descriptor,\n",
        "                stepSize=stepSize,\n",
        "                windowSize=windowSize,\n",
        "                # heatmap=probability_heatmap,\n",
        "            )\n",
        "            features_list.extend(features)\n",
        "            labels_list.extend(labels)\n",
        "        print(\"=\" * 50 + \"Done\" + \"=\" * 50)\n",
        "        name = mode + \"_\" + class_name\n",
        "        export_features(\n",
        "            export_path=root_path,\n",
        "            name=name,\n",
        "            feature_name=\"alex\",\n",
        "            feature_list=features_list,\n",
        "        )\n",
        "        export_features(\n",
        "            export_path=root_path,\n",
        "            name=name,\n",
        "            feature_name=\"labels_alex\",\n",
        "            feature_list=labels_list,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math \n",
        "for i in range(100):\n",
        "    if labels_list[i] == 1:\n",
        "        print(labels_list[i])\n",
        "        f_size = int(math.sqrt(len(features_list[i])))\n",
        "        plt.imshow(features_list[i].reshape(f_size,f_size), cmap='gray')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Machine Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploit crowded regions - Results are not good"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 531,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_list = ['hog', 'alex', 'hog_canny']\n",
        "\n",
        "train_features_list = []\n",
        "train_labels = None\n",
        "test_features_list = []\n",
        "test_labels = None\n",
        "\n",
        "for feature_name in feature_list:\n",
        "    # Load the dictionary from the .npz file\n",
        "    train_fracture = np.load(os.path.join(root_path, f'train_fracture_{feature_name}.npy'), allow_pickle=True)\n",
        "    train_normal = np.load(os.path.join(root_path, f'train_normal_{feature_name}.npy'), allow_pickle=True)\n",
        "    train_fracture_labels = np.load(os.path.join(root_path, f'train_fracture_labels_{feature_name}.npy'), allow_pickle=True)\n",
        "    train_normal_labels = np.load(os.path.join(root_path, f'train_normal_labels_{feature_name}.npy'), allow_pickle=True)\n",
        "\n",
        "    test_fracture = np.load(os.path.join(root_path, f'test_fracture_{feature_name}.npy'), allow_pickle=True)\n",
        "    test_normal = np.load(os.path.join(root_path, f'test_normal_{feature_name}.npy'), allow_pickle=True)\n",
        "    test_fracture_labels = np.load(os.path.join(root_path, f'test_fracture_labels_{feature_name}.npy'), allow_pickle=True)\n",
        "    test_normal_labels = np.load(os.path.join(root_path, f'test_normal_labels_{feature_name}.npy'), allow_pickle=True)\n",
        "\n",
        "    train_features = np.concatenate([train_fracture, train_normal])\n",
        "    train_labels= np.concatenate([train_fracture_labels, train_normal_labels])\n",
        "    train_indices = np.where(train_labels!= -1)[0]\n",
        "    train_features = train_features[train_indices]\n",
        "    train_labels= train_labels[train_indices]\n",
        "\n",
        "    test_features= np.concatenate([test_fracture, test_normal])\n",
        "    test_labels = np.concatenate([test_fracture_labels, test_normal_labels])\n",
        "    test_indices = np.where(test_labels!= -1)[0]\n",
        "    test_features = test_features[test_indices]\n",
        "    test_labels = test_labels[test_indices]\n",
        "    \n",
        "    # Append to the list\n",
        "    train_features_list.append(train_features)\n",
        "    test_features_list.append(test_features)\n",
        "\n",
        "# Concatenate the features\n",
        "train_features = np.concatenate(train_features_list, axis=1)\n",
        "test_features = np.concatenate(test_features_list, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hog Feature: 576\n",
        "\n",
        "Gabor Feature: 49\n",
        "\n",
        "HogCanny Feature: 324\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 503,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(list(range(len(train_features))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 504,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the dataset into majority and minority classes\n",
        "X_majority = train_features[train_labels == 0]\n",
        "y_majority = train_labels[train_labels == 0]\n",
        "X_minority = train_features[train_labels == 1]\n",
        "y_minority = train_labels[train_labels == 1]\n",
        "\n",
        "# Downsample the majority class\n",
        "X_majority_downsampled, y_majority_downsampled = resample(X_majority,\n",
        "                                                        y_majority,\n",
        "                                                        replace=False,\n",
        "                                                        n_samples=len(y_minority),\n",
        "                                                        random_state=42)\n",
        "\n",
        "# Combine the downsampled majority class with the minority class\n",
        "X_balanced = np.vstack((X_majority_downsampled, X_minority))\n",
        "y_balanced = np.hstack((y_majority_downsampled, y_minority))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 505,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 1]), array([1835, 1835]))"
            ]
          },
          "execution_count": 505,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(y_balanced, return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 506,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 507,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((array([0, 1]), array([5979, 1835])), (array([0, 1]), array([1996,  453])))"
            ]
          },
          "execution_count": 507,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(train_labels, return_counts=True), np.unique(test_labels, return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 508,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "test_features = scaler.transform(test_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 509,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mrmr\n",
        "import pandas as pd\n",
        "\n",
        "X_train_pd = pd.DataFrame(X_train)\n",
        "y_train_pd = pd.Series(y_train)\n",
        "test_features_pd = pd.DataFrame(test_features)\n",
        "\n",
        "from mrmr import mrmr_classif\n",
        "### Feature Selection - 600 give the best result\n",
        "selected_features = mrmr_classif(X=X_train_pd, y=y_train_pd, K=600)\n",
        "print(selected_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 510,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_val_pd = pd.DataFrame(X_val)\n",
        "\n",
        "X_train = X_train_pd[selected_features].values\n",
        "X_val = X_val_pd[selected_features].values\n",
        "test_features = test_features_pd[selected_features].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 494,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 511,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-33 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-33 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-33 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-33 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-33 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-33 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-33 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-33 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-33 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-33 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-33 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-33 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-33 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-33 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-33 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-33 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-33 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-33 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-33 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-33\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, class_weight=&#x27;balanced&#x27;, degree=7, gamma=&#x27;auto&#x27;, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" checked><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=100, class_weight=&#x27;balanced&#x27;, degree=7, gamma=&#x27;auto&#x27;, probability=True)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=100, class_weight='balanced', degree=7, gamma='auto', probability=True)"
            ]
          },
          "execution_count": 511,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model = lgb.LGBMClassifier(learning_rate=0.05, n_estimators=150)\n",
        "model = SVC(C=100, kernel='rbf', gamma='auto', probability=True, degree=7, class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 512,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.80      0.79       367\n",
            "           1       0.80      0.78      0.79       367\n",
            "\n",
            "    accuracy                           0.79       734\n",
            "   macro avg       0.79      0.79      0.79       734\n",
            "weighted avg       0.79      0.79      0.79       734\n",
            "\n",
            "[[293  74]\n",
            " [ 79 288]]\n",
            "f1-score: 0.791543460465427\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the valid set\n",
        "y_pred = model.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print('f1-score:', f1_score(y_val, y_pred, average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hard Mining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {},
      "outputs": [],
      "source": [
        "def identify_hard_negatives(X_test, y_test, classifier):\n",
        "    predictions = classifier.predict(X_test)\n",
        "    misclassified_indices = np.where(predictions != y_test)[0]\n",
        "    hard_negatives = [X_test[i] for i in misclassified_indices]\n",
        "    hard_negative_labels = [y_test[i] for i in misclassified_indices]\n",
        "    return np.array(hard_negatives), np.array(hard_negative_labels)\n",
        "\n",
        "def hard_negative_mining(X_train, y_train, X_test, y_test, classifier, iterations=5):\n",
        "    for _ in range(iterations):\n",
        "        # Identify hard negatives\n",
        "        hard_negatives, hard_negative_labels = identify_hard_negatives(X_test, y_test, classifier)\n",
        "        \n",
        "        # Update training set\n",
        "        X_train = np.concatenate((X_train, hard_negatives), axis=0)\n",
        "        y_train = np.concatenate((y_train, hard_negative_labels), axis=0)\n",
        "\n",
        "        # Retrain classifier\n",
        "        classifier.fit(X_train, y_train)\n",
        "\n",
        "        # Optional: Evaluate classifier on the test set after each iteration\n",
        "        y_pred = classifier.predict(X_test)\n",
        "        print(f\"Iteration {_ + 1}\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 477,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       367\n",
            "           1       0.98      0.97      0.98       367\n",
            "\n",
            "    accuracy                           0.98       734\n",
            "   macro avg       0.98      0.98      0.98       734\n",
            "weighted avg       0.98      0.98      0.98       734\n",
            "\n",
            "Iteration 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       367\n",
            "           1       1.00      1.00      1.00       367\n",
            "\n",
            "    accuracy                           1.00       734\n",
            "   macro avg       1.00      1.00      1.00       734\n",
            "weighted avg       1.00      1.00      1.00       734\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = hard_negative_mining(X_train, y_train, X_val, y_val, model, iterations=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 478,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.79      0.86      1996\n",
            "           1       0.45      0.75      0.56       453\n",
            "\n",
            "    accuracy                           0.78      2449\n",
            "   macro avg       0.69      0.77      0.71      2449\n",
            "weighted avg       0.84      0.78      0.80      2449\n",
            "\n",
            "[[1579  417]\n",
            " [ 112  341]]\n",
            "f1-score: 0.8022605870765308\n"
          ]
        }
      ],
      "source": [
        "y_true = test_labels\n",
        "y_pred = model.predict(test_features)\n",
        "\n",
        "# Evaluate the model on the valid set\n",
        "print(classification_report(y_true, y_pred))\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print('f1-score:', f1_score(y_true, y_pred, average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = 'models/weights/fast_region_proposal.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['models/weights/hog_alex_canny.pkl']"
            ]
          },
          "execution_count": 216,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Export model\n",
        "joblib.dump(model, model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = joblib.load(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = joblib.load('models/weights/scaler.pkl')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
